{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1gL2DEfNRGu"
   },
   "source": [
    "# Machine Learning in Python\n",
    "\n",
    "## HSE, 2023-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdTH3pxXFLxw"
   },
   "source": [
    "### Home Assignment #1. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk5URBvkFLxx"
   },
   "source": [
    "Assignment completed by:\n",
    "\n",
    "    (insert your last name and first name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqVyveO4FLxx"
   },
   "source": [
    "### General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A0wmBWwFLxx"
   },
   "source": [
    "__Publication date:__ 16.05.2024\n",
    "\n",
    "__Deadline:__ 04:00 24.05.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qK8Ari9eFLxz"
   },
   "source": [
    "### Grading and penalties\n",
    "\n",
    "The number of points for each problem in this homework assignment is listed next to the problem condition.\n",
    "\n",
    "The homework grade is calculated using the following formula:\n",
    "\n",
    "$$\n",
    "s \\times 10/53 ,\n",
    "$$\n",
    "\n",
    "where $s$ is the number of points you have scored in total for all tasks.\n",
    "\n",
    "For submitting an assignment after the deadline, a penalty of 1 **secondary** point per day is applied to the final grade for the assignment, but the delay cannot exceed one week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEGThfK6FLx0"
   },
   "source": [
    "__WARNING!__ Homework is done independently. “Similar” solutions are considered plagiarism and all students involved (including those who have been copied from) cannot get more than 0 points for it.\n",
    "\n",
    "Also, don't forget that all solutions are run through a special new anti-plagiarism system for Jupyter notebooks, which detects cross “similarities” between different notebooks, as well as solutions generated by a neural network. Such works will also mandatorily be regarded as plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNja-u8vFLx0"
   },
   "source": [
    "### Submission format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H-cf8uaFLx0"
   },
   "source": [
    "You upload your solution on the HA to [Anytask](https://anytask.org/) system. You need to upload a file with the extension .ipynb (Python notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEVawss2FLxy"
   },
   "source": [
    "### About the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXNpYAFdFLxz"
   },
   "source": [
    "In this assignment, we will practice working with linear algebra and, specifically, with the PCA algorithm. The goal of the assignment is to try to compress the soundtrack of a Beethoven melody using this dimensionality reduction algorithm, which we have discussed in detail in seminars and lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "695Wv5Sl3qLx"
   },
   "source": [
    "First, let's import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxhawxri-zK7"
   },
   "outputs": [],
   "source": [
    "# Needed to read and write audio files\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# This is to play audio files directly in Notebook\n",
    "from IPython.display import Audio\n",
    "\n",
    "# And this is the standard set of data analysis libraries required for this assignment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from ipywidgets import HBox, VBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbW6iTq35vCU"
   },
   "source": [
    "Let's download the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjpPcxuU52kK"
   },
   "source": [
    "Let's read the audio track using wavfile:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCbvIMhM-fjc"
   },
   "outputs": [],
   "source": [
    "samplerate, data = wavfile.read('Beethoven_Violin_Sonata_Op_96_first_movement_bars_1-22.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj-kEh2G_CE6"
   },
   "source": [
    "In the cell above we see a certain `samplerate`. This variable stores the samplerate by default; the standard value for audio is 44100 Hz.\n",
    "\n",
    "For those who are not very familiar with sound encoding and recording methods (aka those who didn't pass the 'EGE' in computer science at school :) ), - samplerate shows how many consecutive elements of the array with the signal encode a sound of 1 second duration.\n",
    "\n",
    "You can learn more about sound encoding [here](https://ru.wikipedia.org/wiki/Кодирование_звуковой_информации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewii49Kw8G0z"
   },
   "source": [
    "So, let's see what the sampling rate of our audio track is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRTtnJQF-95F",
    "outputId": "9657cac9-0d69-4ee5-fc83-75276d923251"
   },
   "outputs": [],
   "source": [
    "samplerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X8RSEr98gOr"
   },
   "source": [
    "If you divide the length of the signal array by `samplerate`, you will get the duration of the audio track in seconds. At least, you should get this result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mBt7kZgH-97Q",
    "outputId": "723cec9d-59ae-4b04-af64-fd5afff760f8"
   },
   "outputs": [],
   "source": [
    "len(data) / samplerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVLsvdIz8wS6"
   },
   "source": [
    "Forty-five seconds. Does that sound about right? Compare it to the length of the track by running it on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzN7K-hz9aGC"
   },
   "source": [
    "Note also that the sound is stereo, as the signal is encoded with two channels (for the left and right speaker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rSZCrJTAF-W",
    "outputId": "4186e5f3-4286-4c0f-ce2b-e177ae39e2ae"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cPWoFhF9ssj"
   },
   "source": [
    "Draw the signals in both channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "mVJaqGY5APCo",
    "outputId": "e8982168-d5d6-450c-d7bd-cde7523f9c25"
   },
   "outputs": [],
   "source": [
    "# Channel 1\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(data[:,0])\n",
    "plt.show()\n",
    "\n",
    "# Channel 2\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(data[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrLOeXHV9zUc"
   },
   "source": [
    "Here it is - the legendary “cardiogram” sound we are all familiar with! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2XcZW7k-EH9"
   },
   "source": [
    "So now let's average the channels and get a mono sound, which will be much easier to work with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_IvCJzCAW8b",
    "outputId": "d648527b-73b1-4e79-dec4-0298a392fbbf"
   },
   "outputs": [],
   "source": [
    "mono_sound = np.mean(data, axis=1)\n",
    "mono_sound.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp6Bj5u_-q3T"
   },
   "source": [
    "And now we're finally ready to hear what we have to compress! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "kX1NS2aaAgkE",
    "outputId": "19c57f43-f8be-4828-dd24-3118a57fd27a"
   },
   "outputs": [],
   "source": [
    "Audio(mono_sound, rate = samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tPjXciOAB-S"
   },
   "source": [
    "Pretty, isn't it? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE9nggm7AAxy"
   },
   "source": [
    "For convenience, we will also trim the signal array so that it can be easily divided into equal parts. These parts will form the dataset that you need to compress using the methods you know.\n",
    "\n",
    "In fact, the method is very similar to the one we used to compress the picture at the seminar by splitting it into rectangular sub-pictures - only here the task is even simpler :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ntt7wfSnA05E"
   },
   "outputs": [],
   "source": [
    "mono_sound_to_cut = mono_sound[:1990000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mV8YQSVBRLm"
   },
   "source": [
    "Let's check that our sound is now just a vector of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6ysNa1zJ2tV",
    "outputId": "c244336d-58e0-4963-b81b-891d7381cd81"
   },
   "outputs": [],
   "source": [
    "mono_sound_to_cut.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTUYUPcCBcg7"
   },
   "source": [
    "Great, everything is absolutely ready!\n",
    "\n",
    "Well, that's the end of our mission; now it's your turn! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge67s_evBOZ4"
   },
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJo-et5wJut4"
   },
   "source": [
    "\n",
    "#### 1.1. (2 points)\n",
    "Write a function that will split the signal into equal parts of length 1000 and create a dataset represented as a two-dimensional array (a matrix of objects-features), where each part of the signal of length 1000 is in a separate row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhWHPNaiJgGN"
   },
   "outputs": [],
   "source": [
    "def audio_to_matrix(np_array_data, sample_len=1000): # разбиваем аудио на матрицу с шагом sample_len\n",
    "    return np.array([np_array_data[i:i+sample_len] for i in range(0, len(np_array_data), sample_len)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB-5QutLJg27"
   },
   "source": [
    "#### 1.2. (3 points)\n",
    "\n",
    "Write a function that translates your `matrix` back into an audio signal. In other words, the function unwraps data from a matrix of size `(number of objects, 1000)` into a vector of length `(number of objects * 1000)`.\n",
    "\n",
    "Run the function and check that everything works correctly by playing the “restored” signal in your notebook - this signal should be exactly the same as the original one (because, in fact, it is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cu7WGVPYB47z"
   },
   "outputs": [],
   "source": [
    "sample_len = 1000\n",
    "maxtix_audio = audio_to_matrix(mono_sound_to_cut, sample_len)\n",
    "maxtix_audio.shape # проверим, что размерность матрицы соответствует ожидаемой\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_audio(matrix): # восстанавливаем аудио из матрицы\n",
    "    return matrix.flatten()\n",
    "\n",
    "check_audio = matrix_to_audio(maxtix_audio)\n",
    "check_audio.shape # проверим, что размерность восстановленного аудио соответствует оригиналу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Audio(check_audio, rate = samplerate) # послушаем, как сказано в задании, что восстановлено верно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# и не доверяем своим ушам, проверим, что восстановленное аудио соответствует оригиналу\n",
    "res = np.equal(mono_sound_to_cut, check_audio).all().item()\n",
    "\n",
    "widgets.Valid(\n",
    "    value=res,\n",
    "    description=('They are equal' if res else 'They are not equal'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sfw3ibiB8ua"
   },
   "source": [
    "### 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHf0fecRj56w"
   },
   "source": [
    "#### 2.1. (3 points)\n",
    "\n",
    "Perform a PCA transformation of our matrix and get the data compressed into a lower dimensional space.\n",
    "\n",
    "_Hint. At this stage, we have our \"dataset\" with 1000 \"features\" and we want to reduce the number of \"features\" using the PCA method. You are free to choose the number of components, but initially, it is advisable not to choose too small a number. This way, if the result is poor, it will be easier to determine whether the number of components was insufficient or if there was an error somewhere else :)_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjk0u2MGLgvU"
   },
   "outputs": [],
   "source": [
    "features_num = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtix_audio = audio_to_matrix(mono_sound_to_cut, sample_len)\n",
    "\n",
    "def matrix_audio_updater(value):\n",
    "    global pca\n",
    "    global pca_maxtix_audio\n",
    "    global audio_2D_restored\n",
    "    pca = PCA(n_components=value)\n",
    "    pca.fit(maxtix_audio)\n",
    "    pca_maxtix_audio = pca.transform(maxtix_audio)\n",
    "    audio_2D_restored = pca.inverse_transform(pca_maxtix_audio)\n",
    "    print(\"pca_maxtix_audio shape: \", pca_maxtix_audio.shape)\n",
    "    print(\"audio_2D_restored shape: \", audio_2D_restored.shape)\n",
    "\n",
    "interact(matrix_audio_updater, value=(1, sample_len,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIdKtiIOLhWH"
   },
   "source": [
    "#### 2.2. (4 points)\n",
    "\n",
    "Visualize our \"objects\" in a clear form on a plane. Draw conclusions from their appearance.\n",
    "\n",
    "_Hint. To do this, you need to apply PCA in some special way, which we also discussed in the seminar._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_audio_columns(index): # не более чем дань образцу в конспектах\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.scatter(maxtix_audio[:, index], maxtix_audio[:, index+1], alpha=0.7, color='blue')\n",
    "    plt.scatter(audio_2D_restored[:, index], audio_2D_restored[:, index+1], color='red', alpha=0.7)\n",
    "    plt.show()\n",
    "    # plt.pause(0.25)\n",
    "\n",
    "interact(plot_audio_columns, index=(0, features_num-1, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio_rows(index): # Если при широком разбросе синих точек красные выдают линию, значит восстановить аудио уже не особо получилось\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.scatter(range(sample_len), maxtix_audio[index], alpha=0.7, color='blue')\n",
    "    plt.scatter(range(sample_len), audio_2D_restored[index], color='red', alpha=0.7)\n",
    "    plt.show()\n",
    "    # plt.pause(0.25)\n",
    "\n",
    "interact(plot_audio_rows, index=(0, features_num-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(matrix_to_audio(audio_2D_restored), rate = samplerate) # послушаем, что получилось\n",
    "# в целом, при 95 компонентах вполне качество восстановления хорошее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv-Ts0W7lZUR"
   },
   "source": [
    "#### 2.3. (4 points)\n",
    "\n",
    "Create a scatter plot of the dataset in space using color. Draw conclusions from this graph. What is depicted overall?\n",
    "\n",
    "_Hint. That's what we did in the seminar too. This is another special application of PCA._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzolLR40CjF1"
   },
   "outputs": [],
   "source": [
    "def audio_pca(audio_matrix, n_components=20, visualization=True):\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    Y = pca.fit_transform(audio_matrix)\n",
    "    X_hat = pca.inverse_transform(Y)\n",
    "\n",
    "    if visualization:\n",
    "        pca_vis = PCA(n_components=3) # прям как в конспектах\n",
    "        Y_vis = pca_vis.fit_transform(audio_matrix)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.scatter(Y_vis[:, 0], Y_vis[:, 1], c=Y_vis[:, 2], alpha=0.5)\n",
    "        plt.xlabel('Projection onto the first principal component')\n",
    "        plt.ylabel('Projection onto the second principal component')\n",
    "        plt.title('Projection onto the first three components (third - color)')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    return X_hat\n",
    "\n",
    "compressed_audio_matrix = audio_pca(maxtix_audio, n_components=3, visualization=True)\n",
    "\n",
    "for num_components in [900, 500, 100, 75, 60, 50, 40, 30, 20, 10, 5, 3]:\n",
    "    compressed_audio_matrix = audio_pca(maxtix_audio, n_components=num_components, visualization=False)\n",
    "    compressed_audio = matrix_to_audio(compressed_audio_matrix)\n",
    "    print(f\"Number of components: {num_components}\")\n",
    "    display(Audio(compressed_audio, rate = samplerate))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельная услада для ушей - слышать, что при сжатии до 3 компонент мы слышим разве что \"басы\" (в данном случае это пианоно)\n",
    "\n",
    "А вот тонкие звуки скрипки и флейты мы не слышим и при сжатии до 10 компонент.\n",
    "\n",
    "Что значит скрипка для ценителей искусства, которым нужно как можно меньше сжатия, а вот современные меломаны, которые слушают музыку в машине, могут и не заметить разницы между 3 и 10 компонентами.\n",
    "\n",
    "Дальше приводится немного дополнительной визуализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "from ipywidgets import IntSlider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_interactive(X):\n",
    "    def update_plot(n_components):\n",
    "\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(X)\n",
    "        X_pca = pca.transform(X)\n",
    "\n",
    "        # очистим с прошлого раза\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(X[:, 0], X[:, 1], alpha=0.7, label='Original Data')\n",
    "        \n",
    "        for i in range(n_components):\n",
    "            # Get eigenvector * eigenvalue (for scaling)\n",
    "            vector = pca.components_[i] * np.sqrt(pca.explained_variance_[i])\n",
    "            # Plot eigenvector as an arrow\n",
    "            plt.arrow(pca.mean_[0], pca.mean_[1], vector[0], vector[1],\n",
    "                      head_width=0.2, head_length=0.3, color=f'C{i}', label=f'PC{i+1}')\n",
    "\n",
    "            # Calculate ellipse parameters for visualization\n",
    "            eigenvalue = pca.explained_variance_[i]\n",
    "            vector = pca.components_[i]\n",
    "            angle = np.arctan2(vector[1], vector[0])\n",
    "            angle = np.degrees(angle) \n",
    "\n",
    "            # Handle the last ellipse separately to avoid the IndexError\n",
    "            if i < n_components - 1:\n",
    "                ellipse = Ellipse(pca.mean_, width=np.sqrt(eigenvalue) * 2, height=np.sqrt(pca.explained_variance_[i+1]) * 2,\n",
    "                                  angle=angle, edgecolor=f'C{i}', facecolor='none', linewidth=2, alpha=0.7)\n",
    "            else:\n",
    "                # For the last ellipse, use the eigenvalue of the last component for both width and height\n",
    "                ellipse = Ellipse(pca.mean_, width=np.sqrt(eigenvalue) * 2, height=np.sqrt(eigenvalue) * 2,\n",
    "                                  angle=angle, edgecolor=f'C{i}', facecolor='none', linewidth=2, alpha=0.7)\n",
    "            plt.gca().add_patch(ellipse)\n",
    "        \n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.title('Interactive PCA')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    interact(update_plot, n_components=IntSlider(min=1, max=20, step=1, value=2, description='Components:'))\n",
    "    \n",
    "plot_pca_interactive(maxtix_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKJYxUGgCkXq"
   },
   "source": [
    "### 3\n",
    "\n",
    "We need to deal with the actual \"compression\" of the sound and verify the correctness of our actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6lEkwKXNJGi"
   },
   "source": [
    "#### 3.1. (4 points)\n",
    "\n",
    "Perform inverse PCA transformation of the compressed data and get a “matrix” with the compressed sound. What will be the size of the resulting matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59G3sAXTNJQa"
   },
   "outputs": [],
   "source": [
    "# Хоть мы это делали ранее при визуализации, но проделаем это наглядно\n",
    "\n",
    "maxtix_audio = audio_to_matrix(mono_sound_to_cut, sample_len)\n",
    "print (\"maxtix_audio shape: \", maxtix_audio.shape)\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(maxtix_audio)\n",
    "pca_maxtix_audio = pca.transform(maxtix_audio)\n",
    "print (\"pca_maxtix_audio shape: \", pca_maxtix_audio.shape)\n",
    "audio_2D_restored = pca.inverse_transform(pca_maxtix_audio)\n",
    "print (\"audio_2D_restored shape: \", audio_2D_restored.shape)\n",
    "\n",
    "# Ну вот как мы видим, размерность восстановленного аудио совпадает с оригиналом\n",
    "# То есть мы прошли через узкое горлышко шириной в 50 компонент и восстановили аудио обратно в 1000 сегментов, частота звука осталась прежней."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmLnumv4NJfQ"
   },
   "source": [
    "#### 3.2. (4 points)\n",
    "\n",
    "Convert the “matrix” obtained in the previous step into a playable signal (our “compressed” mono sound). Play the result `(Audio(YOUR_RESULT, rate = samplerate)`.\n",
    "\n",
    "Does the resulting sound resemble the original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7x_VAiJQCnNF"
   },
   "outputs": [],
   "source": [
    "restored_audio = matrix_to_audio(audio_2D_restored)\n",
    "\n",
    "Audio(restored_audio, rate = samplerate) # послушаем, что получилось\n",
    "\n",
    "# Does the resulting sound resemble the original? - Ответ зависит от количества компонент, которые мы использовали для сжатия\n",
    "# В данном случае, для 100 компонент, качество восстановления довольно хорошее\n",
    "# Для 10 - уже очень печальное"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su-TpE2jOMZm"
   },
   "source": [
    "#### 3.3. (8 points)\n",
    "\n",
    "Conduct a study of the dependence of sound quality on the number of components.\n",
    "\n",
    "Determine by ear the minimum number of components at which the sound is almost indistinguishable from the original.\n",
    "\n",
    "Add two variants of the soundtrack to the cells: the original and the one you have chosen. Specify the number of components you have chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1awFP0lWaFJ"
   },
   "source": [
    "_Hint. Try filtering the signal with the `gaussian_filter1d` function from `scipy.ndimage`. This will help remove the unpleasant shot noise when the compression is severe. You'll see what it's all about when you try it in practice._\n",
    "\n",
    "_Sample code for filtering: `Audio(gaussian_filter1d(mono_sound_compressed, 2), rate = samplerate)`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение используемой функции лежит внизу, не забудьте ее запустить сначала\n",
    "# перенёс туда, так как только в последнем задании сказано, обернуть всё в функцию\n",
    "\n",
    "print (\"Original audio: \")\n",
    "display(Audio(mono_sound_to_cut, rate = samplerate))\n",
    "print (\"Compressed audio: \")\n",
    "com_number = 70\n",
    "display(Audio(get_compressed_audio(mono_sound_to_cut, com_number, 1000, True), rate = samplerate))\n",
    "print(\"Compession rate: \", 1000 / com_number, \" times\")\n",
    "\n",
    "# widgets.HBox(audio_widgets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG6sPku9Uslp"
   },
   "source": [
    "#### 3.4. (6 points)\n",
    "Argumentatively answer the following questions:\n",
    "1. Q1\n",
    "    1. Is the number of components you have chosen too many or too few?\n",
    "    2. How can you determine this?\n",
    "2. Q2\n",
    "    1. To what extent can the sound be compressed in this way?\n",
    "    2. What memory optimization did you achieve in the process?\n",
    "3. If we are given a different soundtrack, we would need to do all the same things to compress the sound. How do we automatically select the number of components and is it possible?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcEriqNmuM1E"
   },
   "source": [
    "#### Ответы на вопросы\n",
    "\n",
    "1. Q1\n",
    "    1. Слишком мало или слишком много компонент для чего? Для достижения какой цели? В соответствии с условием задачи я выбрал столько компонент, сколько необходимо и достаточно чтобы звук был похож на оригинал. Если бы я выбрал меньше компонент, то звук был бы слишком сжат и не похож на оригинал. Если бы я выбрал больше компонент, то звук был бы похож на оригинал, но сжатие было бы неэффективным.\n",
    "    2. Как и было сказано в задании - по звуку. В зависимости от конкретного устройства воспроизведения, будь то колонки, наушники-затычки или студийные накладные наушники, а также в зависимости от конкретного человека оценки качества сжатого аудио будут различны. Поэтому в любом случае, при пыпытке достичь наилучшей возможной степени сжатия \"без потерь\", результат будет субъективен.\n",
    "2. Q2\n",
    "    1. В зависимости от желаемой степени качества - от 10 до 20, в некоторых случаях до 30 раз от изначального размера, если нас будет интересовать только что-то похожее на азбуку морзе.\n",
    "    2. Конкретно при выборе сжатия до 70 компонент при длинне сэмпла 1000, мы сжимаем звук в 14 раз. То есть сэкономили ~93% памяти. Что скорее говорит о низком качестве моего устройства воспроизведения и моего слуха, чем о качестве сжатия.\n",
    "3. Наилучшим способом определения количества компонент является метод проб и ошибок. Но если у нас есть много данных, то можно использовать методы кросс-валидации и поиска оптимального числа компонент по критериям качества. Например, поиск минимального числа компонент, при котором качество сжатия не ухудшается. Для этого нужно будет ввести некоторый критерий качества. Чем лучше будет критерий, чем больше он будет отражать качество именно то, которое воспринимает человек, тем лучше будет результат.\n",
    "Также, ввиду того, что было замечено, что при уменьшении числа компонент в первую очередь теряются высокие частоты, то можно использовать методы анализа спектра звука для определения оптимального числа компонент. Например, если в звуке преобладают высокие частоты, то можно сделать вывод, что нужно больше компонент. Если же в звуке преобладают низкие частоты, то можно сделать вывод, что нужно меньше компонент. Конкретные численные значения можно вычислять эвристиками на основе анализа спектра звука."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6VSR-JNux9i"
   },
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0nMtm7lSP73"
   },
   "source": [
    "#### Extra Research. (15 points).\n",
    "  \n",
    "  - Wrap the resulting audio compression code in one or more functions.\n",
    "\n",
    "  - Investigate how the compression ratio - the ratio of the size of the parts into which the signal was divided in task 1.1 to the size of the space into which you compressed the data using PCA - affects the sound, according to your subjective feelings. Starting from what compression level is the loss of audio track quality noticeable? (Both with and without `gaussian_filter1d` filtering).\n",
    "\n",
    "  - What does the compression ratio mean for PCA? For a large audio recording (3 min, for example), would we want to break it into more, less, or the same number of segments as the proposed audio recording? Why?\n",
    "\n",
    "  - Is there any way to automatically select the compression ratio? What is it responsible for in our task? How does the compression ratio affect the sound? Why does it affect the sound in this way?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Wrap the resulting audio compression code in one or more functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjNFEEzKSQvE"
   },
   "outputs": [],
   "source": [
    "# так как в конце задания требуется сравнить качество восстановленного аудио с оригиналом, напишем функцию для этого\n",
    "def get_compressed_audio(mono_sound, n_components, sample_len, use_gaussian_filter):\n",
    "    maxtix_audio = audio_to_matrix(mono_sound, sample_len)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(maxtix_audio)\n",
    "    pca_maxtix_audio = pca.transform(maxtix_audio)\n",
    "    audio_2D_restored = pca.inverse_transform(pca_maxtix_audio)\n",
    "    if use_gaussian_filter:\n",
    "        audio_2D_restored = gaussian_filter1d(audio_2D_restored, 2)\n",
    "    return matrix_to_audio(audio_2D_restored)\n",
    "\n",
    "# СКО может быть и не лучшим вариантом, но идеала в данном случае нет\n",
    "def score_compressed_audio(mono_sound, compressed_audio):\n",
    "    sm = np.sum((mono_sound - compressed_audio)**2)\n",
    "    return sm / len(mono_sound)\n",
    "\n",
    "def test_by(sound, n_comps, sample_len, use_gaussian_filter):\n",
    "    boxes = []\n",
    "    for n in n_comps:\n",
    "        box = widgets.Output()\n",
    "        a = get_compressed_audio(sound, n, sample_len, use_gaussian_filter)\n",
    "        s = score_compressed_audio(sound, a)\n",
    "        cr = sample_len / n\n",
    "        s = '{0:.2f}'.format(s / cr)\n",
    "        with box:\n",
    "            display(widgets.Label(str(n) + ' cmps, ' + ('with' if use_gaussian_filter else 'no') + ' filter' + ' Score: ' + s + \n",
    "                                  '; '+'{0:.2f}'.format(cr)  + 'x; ' + str(sample_len) + ' s_len'),\n",
    "                    Audio(a, rate = samplerate))\n",
    "        boxes.append(box)\n",
    "    return HBox(boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Investigate how the compression ratio - the ratio of the size of the parts into which the signal was divided in task 1.1 to the size of the space into which you compressed the data using PCA - affects the sound, according to your subjective feelings. Starting from what compression level is the loss of audio track quality noticeable? (Both with and without `gaussian_filter1d` filtering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = [100, 70, 50, 30, 10, 3]\n",
    "\n",
    "v_box = [test_by(mono_sound_to_cut, n_comps, 10000, False),\n",
    "         test_by(mono_sound_to_cut, n_comps, 10000, True),\n",
    "         test_by(mono_sound_to_cut, n_comps, 1000, False),\n",
    "         test_by(mono_sound_to_cut, n_comps, 1000, True),\n",
    "         test_by(mono_sound_to_cut, n_comps, 500, False),\n",
    "         test_by(mono_sound_to_cut, n_comps, 500, True),\n",
    "         test_by(mono_sound_to_cut, n_comps, 100, False),\n",
    "         test_by(mono_sound_to_cut, n_comps, 100, True),]\n",
    "\n",
    "\n",
    "display(VBox(v_box))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - What does the compression ratio mean for PCA? For a large audio recording (3 min, for example), would we want to break it into more, less, or the same number of segments as the proposed audio recording? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the compression ratio mean for PCA? - отношение между размером частей, на которые мы разбили сигнал в задаче 1.1, к размеру пространства, в которое вы сжали данные с помощью PCA.\n",
    "For a large audio recording (3 min, for example), would we want to break it into more, less, or the same number of segments as the proposed audio recording? Why? - как видно из набора аудиосамплов выше увеличение или уменьшение размера сэмпла может солидно ухудшить качество результата. При значительном уменьшении мы захрепим, при значительном увеличении звук \"поплывёт\", как если бы мы одновременно слышали несколько частей одной и той же мелодии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Is there any way to automatically select the compression ratio? What is it responsible for in our task? How does the compression ratio affect the sound? Why does it affect the sound in this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большую степень сжатия можно применять к аудио, которое содержит меньше высоких частот. Достаточно определить спектрограмму аудио и посмотреть (в кавычках посмотреть, для атоматизации эвристически определить пороги допустимости присутствия для использования того или иного количества компонент) на распределение частот. Если в аудио преобладают низкие частоты, то можно использовать меньше компонент. Если же в аудио преобладают высокие частоты, то придётся использовать больше компонент.\n",
    "\n",
    "Быстрее всего увеличение степени сжатия проявляется в исчезновении высоких частот. Позже, при дальнейшем увеличении степени сжатия уже будут слышны \"хрипы\".\n",
    "\n",
    "Это то, как лично я услышал результаты сжатия. Возможно, у кого-то будет другое мнение.\n",
    "\n",
    "Если углубляться в суть метода PCA, то более точно можно сформулировать, что при уменьшении числа компонент должны исчезать \"детали\", а не высокие частоты. То есть алгоритму PCA в целом всё равно какие закономерности находить - те, которые формируют высокие частоты или низкие. Тем не менее, слышно так, как это слышно. В целом уменьшение конкретных частот обычно характерно для сжатия, которое можно найти в, скажем MP3.\n",
    "\n",
    "Уточняя таким образом предыдущий ответ про автоматизацию, скорее нужно смотереть в спектрограмме не на присутствие высоких частот, а на вид спектрограммы в целом. Скажем, если в спектрограмме более менее одинаково распределены частоты, то это скорее приведёт к тому, что нужно будет использовать больше компонент, так как звук по всей видимости довольно разннобразный и сложный, а если спектрограмма простая, с конкретным пиком, то можно использовать меньше компонент.\n",
    "\n",
    "Тем не менее, такие выводы стоит делать после изучения большого количества данных, например построить сами спектрограммы, сделать это для разного количества компонент, для разных аудио, посмотреть как влияет на спектрограмму в принципе сжатие и так далее."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
